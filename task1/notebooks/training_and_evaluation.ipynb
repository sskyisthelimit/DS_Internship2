{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/sskyisthelimit/DS_Internship2.git\n%cd DS_Internship2/task1/\n!python3 -m pip install -r requirements.txt","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-02-21T14:28:28.514304Z","iopub.execute_input":"2025-02-21T14:28:28.514616Z","iopub.status.idle":"2025-02-21T14:28:46.334781Z","shell.execute_reply.started":"2025-02-21T14:28:28.514574Z","shell.execute_reply":"2025-02-21T14:28:46.333699Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'DS_Internship2'...\nremote: Enumerating objects: 198, done.\u001b[K\nremote: Counting objects: 100% (87/87), done.\u001b[K\nremote: Compressing objects: 100% (64/64), done.\u001b[K\nremote: Total 198 (delta 37), reused 70 (delta 21), pack-reused 111 (from 1)\u001b[K\nReceiving objects: 100% (198/198), 46.99 MiB | 20.46 MiB/s, done.\nResolving deltas: 100% (71/71), done.\n/kaggle/working/DS_Internship2/task1\nCollecting idx2numpy==1.2.3 (from -r requirements.txt (line 1))\n  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: joblib>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.4.2)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.2.2)\nRequirement already satisfied: tqdm>=4.62.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.66.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from idx2numpy==1.2.3->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from idx2numpy==1.2.3->-r requirements.txt (line 1)) (1.16.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->-r requirements.txt (line 3)) (1.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->-r requirements.txt (line 3)) (3.5.0)\nBuilding wheels for collected packages: idx2numpy\n  Building wheel for idx2numpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=d1248fd60b331cd75d3a57b394be7eb3f3abf410cb4913a6bf66ca509e54503d\n  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\nSuccessfully built idx2numpy\nInstalling collected packages: idx2numpy\nSuccessfully installed idx2numpy-1.2.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd src","metadata":{"execution":{"iopub.status.busy":"2025-02-21T14:28:46.338991Z","iopub.execute_input":"2025-02-21T14:28:46.339276Z","iopub.status.idle":"2025-02-21T14:28:46.345074Z","shell.execute_reply.started":"2025-02-21T14:28:46.339195Z","shell.execute_reply":"2025-02-21T14:28:46.344282Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/DS_Internship2/task1/src\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.makedirs(\"/kaggle/working/weights\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-21T14:28:46.346602Z","iopub.execute_input":"2025-02-21T14:28:46.346869Z","iopub.status.idle":"2025-02-21T14:28:46.356357Z","shell.execute_reply.started":"2025-02-21T14:28:46.346845Z","shell.execute_reply":"2025-02-21T14:28:46.355687Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!python3 train.py --datapath ../dataset/ --device \"cuda:0\" --weights_save_dir /kaggle/working/weights/","metadata":{"execution":{"iopub.status.busy":"2025-02-21T14:28:46.357286Z","iopub.execute_input":"2025-02-21T14:28:46.357485Z","iopub.status.idle":"2025-02-21T14:31:02.011593Z","shell.execute_reply.started":"2025-02-21T14:28:46.357464Z","shell.execute_reply":"2025-02-21T14:31:02.010392Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Starting to train CNN\nEpoch 1: 100%|█| 938/938 [00:06<00:00, 143.42batch/s, accuracy=95.6, loss=0.158]\nEpoch 1, Loss: 0.1583, Accuracy: 95.62%\nEpoch 2: 100%|█| 938/938 [00:05<00:00, 165.23batch/s, accuracy=98.5, loss=0.0504\nEpoch 2, Loss: 0.0504, Accuracy: 98.45%\nEpoch 3: 100%|█| 938/938 [00:05<00:00, 168.43batch/s, accuracy=98.8, loss=0.0365\nEpoch 3, Loss: 0.0365, Accuracy: 98.83%\nEpoch 4: 100%|█| 938/938 [00:05<00:00, 168.69batch/s, accuracy=99.1, loss=0.028]\nEpoch 4, Loss: 0.0280, Accuracy: 99.08%\nEpoch 5: 100%|█| 938/938 [00:05<00:00, 169.55batch/s, accuracy=99.2, loss=0.0245\nEpoch 5, Loss: 0.0245, Accuracy: 99.24%\nEpoch 6: 100%|█| 938/938 [00:05<00:00, 168.25batch/s, accuracy=99.3, loss=0.0207\nEpoch 6, Loss: 0.0207, Accuracy: 99.34%\nEpoch 7: 100%|█| 938/938 [00:05<00:00, 168.47batch/s, accuracy=99.4, loss=0.0166\nEpoch 7, Loss: 0.0166, Accuracy: 99.42%\nEpoch 8: 100%|█| 938/938 [00:05<00:00, 166.25batch/s, accuracy=99.5, loss=0.0149\nEpoch 8, Loss: 0.0149, Accuracy: 99.50%\nEpoch 9: 100%|█| 938/938 [00:05<00:00, 167.39batch/s, accuracy=99.6, loss=0.0111\nEpoch 9, Loss: 0.0111, Accuracy: 99.64%\nEpoch 10: 100%|█| 938/938 [00:05<00:00, 168.43batch/s, accuracy=99.7, loss=0.010\nEpoch 10, Loss: 0.0106, Accuracy: 99.66%\nStarting to train FCNN\nEpoch 1: 100%|█| 938/938 [00:03<00:00, 286.65batch/s, accuracy=90.3, loss=0.346]\nEpoch 1, Loss: 0.3456, Accuracy: 90.30%\nEpoch 2: 100%|█| 938/938 [00:03<00:00, 283.73batch/s, accuracy=95.7, loss=0.143]\nEpoch 2, Loss: 0.1433, Accuracy: 95.73%\nEpoch 3: 100%|██| 938/938 [00:03<00:00, 286.25batch/s, accuracy=97, loss=0.0983]\nEpoch 3, Loss: 0.0983, Accuracy: 97.00%\nEpoch 4: 100%|█| 938/938 [00:03<00:00, 284.10batch/s, accuracy=97.8, loss=0.0727\nEpoch 4, Loss: 0.0727, Accuracy: 97.77%\nEpoch 5: 100%|█| 938/938 [00:03<00:00, 270.45batch/s, accuracy=98.2, loss=0.0586\nEpoch 5, Loss: 0.0586, Accuracy: 98.16%\nEpoch 6: 100%|█| 938/938 [00:03<00:00, 285.59batch/s, accuracy=98.5, loss=0.047]\nEpoch 6, Loss: 0.0470, Accuracy: 98.52%\nEpoch 7: 100%|█| 938/938 [00:03<00:00, 284.46batch/s, accuracy=98.8, loss=0.0381\nEpoch 7, Loss: 0.0381, Accuracy: 98.77%\nEpoch 8: 100%|██| 938/938 [00:03<00:00, 281.11batch/s, accuracy=99, loss=0.0307]\nEpoch 8, Loss: 0.0307, Accuracy: 99.00%\nEpoch 9: 100%|█| 938/938 [00:03<00:00, 285.80batch/s, accuracy=99.1, loss=0.0263\nEpoch 9, Loss: 0.0263, Accuracy: 99.15%\nEpoch 10: 100%|█| 938/938 [00:03<00:00, 283.73batch/s, accuracy=99.3, loss=0.022\nEpoch 10, Loss: 0.0220, Accuracy: 99.27%\nStarting to train RF\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!python3 eval.py --datapath ../dataset/ --device \"cuda:0\" --weights_dir /kaggle/working/weights/","metadata":{"execution":{"iopub.status.busy":"2025-02-21T14:31:02.013650Z","iopub.execute_input":"2025-02-21T14:31:02.014003Z","iopub.status.idle":"2025-02-21T14:31:09.842483Z","shell.execute_reply.started":"2025-02-21T14:31:02.013973Z","shell.execute_reply":"2025-02-21T14:31:09.841636Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/DS_Internship2/task1/src/classifiers.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.model.load_state_dict(torch.load(filename,\nStarting evaluation of CNN\nCNN Evaluation: 100%|█████████████████████| 157/157 [00:00<00:00, 237.62batch/s]\nCNN classification report\n              precision    recall  f1-score   support\n\n           0     0.9919    0.9949    0.9934       980\n           1     0.9947    0.9947    0.9947      1135\n           2     0.9828    0.9942    0.9884      1032\n           3     0.9842    0.9881    0.9862      1010\n           4     0.9918    0.9847    0.9882       982\n           5     0.9854    0.9809    0.9831       892\n           6     0.9855    0.9906    0.9880       958\n           7     0.9864    0.9864    0.9864      1028\n           8     0.9948    0.9867    0.9907       974\n           9     0.9841    0.9792    0.9816      1009\n\n    accuracy                         0.9882     10000\n   macro avg     0.9881    0.9880    0.9881     10000\nweighted avg     0.9882    0.9882    0.9882     10000\n\n/kaggle/working/DS_Internship2/task1/src/classifiers.py:130: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.model.load_state_dict(torch.load(filename,\nStarting evaluation of FCNN\nFCNN Evaluation: 100%|████████████████████| 157/157 [00:00<00:00, 451.93batch/s]\nFCNN classification report\n              precision    recall  f1-score   support\n\n           0     0.9907    0.9776    0.9841       980\n           1     0.9947    0.9877    0.9912      1135\n           2     0.9823    0.9671    0.9746      1032\n           3     0.9762    0.9733    0.9747      1010\n           4     0.9566    0.9868    0.9714       982\n           5     0.9647    0.9798    0.9722       892\n           6     0.9761    0.9812    0.9787       958\n           7     0.9741    0.9864    0.9802      1028\n           8     0.9575    0.9713    0.9643       974\n           9     0.9815    0.9455    0.9631      1009\n\n    accuracy                         0.9757     10000\n   macro avg     0.9754    0.9756    0.9754     10000\nweighted avg     0.9759    0.9757    0.9757     10000\n\nStarting evaluation of RF\nRF Evaluation: 100%|██████████████████████| 157/157 [00:01<00:00, 101.59batch/s]\nRF classification report\n              precision    recall  f1-score   support\n\n           0     0.9700    0.9888    0.9793       980\n           1     0.9912    0.9894    0.9903      1135\n           2     0.9596    0.9671    0.9633      1032\n           3     0.9595    0.9624    0.9609      1010\n           4     0.9725    0.9715    0.9720       982\n           5     0.9730    0.9686    0.9708       892\n           6     0.9739    0.9729    0.9734       958\n           7     0.9743    0.9591    0.9667      1028\n           8     0.9629    0.9589    0.9609       974\n           9     0.9523    0.9504    0.9514      1009\n\n    accuracy                         0.9691     10000\n   macro avg     0.9689    0.9689    0.9689     10000\nweighted avg     0.9691    0.9691    0.9691     10000\n\n","output_type":"stream"}],"execution_count":5}]}