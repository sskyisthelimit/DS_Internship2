{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10796151,"sourceType":"datasetVersion","datasetId":6700331},{"sourceId":10801545,"sourceType":"datasetVersion","datasetId":6704152},{"sourceId":104449,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers pydantic bitsandbytes-cuda110 bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:21:20.942224Z","iopub.execute_input":"2025-02-19T19:21:20.943148Z","iopub.status.idle":"2025-02-19T19:21:33.020884Z","shell.execute_reply.started":"2025-02-19T19:21:20.943107Z","shell.execute_reply":"2025-02-19T19:21:33.019784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/failed-animal-names-1/failed_animal_names.json\") as json_data:\n    prev_failed_animal_names = json.load(json_data)[\"failed_animal_names\"]\n\nprint(prev_failed_animal_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T07:16:44.403101Z","iopub.execute_input":"2025-02-20T07:16:44.403954Z","iopub.status.idle":"2025-02-20T07:16:44.414620Z","shell.execute_reply.started":"2025-02-20T07:16:44.403912Z","shell.execute_reply":"2025-02-20T07:16:44.413590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import List\nimport spacy\nfrom spacy.tokens import DocBin, Span\nimport re\nimport gc \nimport random\n\nrandom.seed(42)\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nmodel_dir = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2/\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False\n)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_dir, \n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float16\n)\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# # Load CSV files\n# animal_df = pd.read_csv(\"/kaggle/input/animal-names/processed_animal_names.csv\")\n# needed_animal_classes = [\"Mammalia\", \"Aves\", \"Arachnida\", \"Insecta\", \"Pisces\", \"Amphibia\", \"Mollusca\", \"Crustacea\", \"Cnidaria\"]\n\n# animal_samples = list(animal_df[animal_df[\"class\"].isin(needed_animal_classes)][\"common_name\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:21:33.022972Z","iopub.execute_input":"2025-02-19T19:21:33.023251Z","iopub.status.idle":"2025-02-19T19:23:15.288514Z","shell.execute_reply.started":"2025-02-19T19:21:33.023225Z","shell.execute_reply":"2025-02-19T19:23:15.287827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"system_prompt = \"\"\"\nYou are an advanced AI trained in natural language processing and synthetic data generation.\nYour task is to read the following animal name and generate 10 unique sentences using given animal name.\nMake main focus on diversifying sentences - sentence structures and words.\n\nMake sure to extract the exact and use string of the animal name without any changes in it.\nFor each sentence, highlight the name of the given animal string by setting \"||\" around it.\nYou are not allowed to use words that may have a meaning of the animal except given animal name.\nDo not provide any explanations.\nOnly respond with the JSON structured data, structure of JSON should be strictly as in examples.\n\n### Example 1:\nInput: 'bald eagle'\n\nOutput:\n[\n    {\n        \"bald eagle\": [\n            \"The majestic ||bald eagle|| soars high above the tranquil lake, its keen eyes scanning for prey.\",\n            \"With powerful wings, the ||bald eagle|| glides effortlessly through the morning sky.\",\n            \"A symbol of strength and freedom, the ||bald eagle|| commands attention wherever it flies.\",\n            \"The sharp talons of the ||bald eagle|| make it a formidable hunter among the skies.\",\n            \"The call of the ||bald eagle|| echoes through the valleys, a sound both haunting and beautiful.\",\n            \"Under the golden sunset, the silhouette of the ||bald eagle|| is a breathtaking sight.\",\n            \"The ||bald eagle|| is often seen perched on rocky cliffs, surveying the world below.\",\n            \"The ||bald eagle|| is easily identifiable by its white head and tail feathers.\",\n            \"From a distance, it was hard to tell that was the ||bald eagle||.\",\n            \"||eagle|| enthusiasts pay much attention to ||bald eagle||, admiring its regal presence and hunting prowess.\"\n        ]\n    }\n]\n\n\n### Example 2:\nInput: 'cow'\n\nOutput:\n[\n    {\n        \"cow\": [\n            \"In the serene meadow, the ||cow|| grazes peacefully under the warm sun.\",\n            \"Once revered in ancient cultures, the ||cow|| holds symbolic meaning even today.\",\n            \"Researchers study the digestion of the ||cow|| to improve agricultural efficiency.\",\n            \"The ||cow||, known for its gentle demeanor, is a beloved farm animal worldwide.\",\n            \"On the rolling hills, the ||cow|| is a symbol of pastoral beauty.\",\n            \"||Cow|| enthusiasts pay much attention for ||cows|| with exceptional milk production.\",\n            \"Farmers appreciate the ||cow|| not only for milk but also for the role of the ||cow|| in sustainable agriculture.\",\n            \"The bell around the ||cow||'s neck jingles as the ||cow|| moves through the pasture.\",\n            \"From ancient myths to modern-day farming, the ||cow|| has always held a special place in human society, symbolizing abundance and nurturing.\",\n            \"The ||cow||'s milk is used to make cheese, yogurt, and butter, highlighting the ||cow||'s importance in the culinary world.\"\n        ]\n    }\n]\n\n\nContinue with the task and stop after generating valid output for the given animal by the user by outputting '### Output ends here.'\nDon't forget this strict rules.\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:23:15.289577Z","iopub.execute_input":"2025-02-19T19:23:15.289840Z","iopub.status.idle":"2025-02-19T19:23:15.295446Z","shell.execute_reply.started":"2025-02-19T19:23:15.289814Z","shell.execute_reply":"2025-02-19T19:23:15.294610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import StoppingCriteria, StoppingCriteriaList\nfrom torch import cuda, LongTensor, FloatTensor\nimport os\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\nfailed_animal_names = []\nimport json\nimport re\n\nimport json\nimport re\n\nimport json\nimport re\n\ndef extract_json_from_response(response):\n    \"\"\"\n    Extracts JSON content from the response string.\n    It looks for the first occurrence of '[' or '{' after the keyword \"Output:\" \n    and uses the last occurrence of the corresponding closing bracket before \"### Output ends here.\".\n    If extraction or parsing fails, returns an empty list.\n    \"\"\"\n    try:\n        # Locate the start of the output segment and the end marker\n        output_index = response.find(\"\\nUser:\")\n        end_index = response.rfind(\"Output ends here\")\n        if output_index == -1 or end_index == -1:\n            print(\"Output or end marker not found\")\n            return []\n        # Consider only the text between \"Output:\" and \"### Output ends here.\"\n        segment = response[output_index:end_index]\n        # Find the first occurrence of '[' or '{' in the segment\n        match = re.search(r'([\\[\\{])', segment)\n        if not match:\n            print(\"No JSON start character found in segment\")\n            return []\n        start_bracket = match.start()\n        json_content = segment[start_bracket:].strip()\n        # Depending on the first character, find the last matching closing bracket\n        if json_content[0] == '[':\n            end_bracket = json_content.rfind(']')\n        else:\n            end_bracket = json_content.rfind('}')\n        if end_bracket == -1:\n            print(\"No closing bracket found\")\n            return []\n        json_content = json_content[:end_bracket+1]\n        # Debug print the extracted JSON content\n        parsed = json.loads(json_content)\n        # Wrap dictionary in a list if needed\n        if not isinstance(parsed, list):\n            parsed = [parsed]\n        return parsed\n    except json.JSONDecodeError as e:\n        print(f\"Failed to decode JSON: {e}\")\n        return []\n\n\n\n\n\ndef create_stopping_criteria(stop_words, tokenizer, device):\n    class StoppingCriteriaSub(StoppingCriteria):\n        def __init__(self, stops = [], device=device, encounters = 1):\n            super().__init__()\n            self.stops = stops = [stop.to(device) for stop in stops]\n\n        def __call__(self, input_ids: LongTensor, scores: FloatTensor) -> bool:\n            last_token = input_ids[0][-1]\n            for stop in self.stops:\n                if tokenizer.decode(stop) == tokenizer.decode(last_token):\n                    return True\n            return False\n\n    stop_word_ids = [tokenizer(stop_word,\n                               return_tensors=\"pt\", \n                               add_special_tokens=False)[\"input_ids\"].squeeze() \n                               for stop_word in stop_words]\n\n    stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_word_ids)])\n    return stopping_criteria\n\n\nstop_words_list = [\"Output ends\"]\nstopping_criteria = None\nif stop_words_list is not None:\n    stopping_criteria = create_stopping_criteria(stop_words_list, tokenizer, device)\n\ndef write_batch_to_json(entities, start_idx):\n    filename = os.path.join(\"/kaggle/working/generated/\", \"entity_\" + str(start_idx) + \".json\")\n    with open(filename, \"w\", encoding='utf-8') as f:\n        json.dump(entities, f)\n        \n\ndef predict_entities_in_batches(test_dataset, model, tokenizer, system_prompt):\n    text_generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\n    with torch.no_grad():\n        for i in tqdm(range(len(test_dataset)), desc=\"Processing batches\"):\n\n            prompt = test_dataset[i]\n            prompt = f\"{prompt}\"\n            chat_input = [\n                f\"{system_prompt}\\nUser: {prompt}\"\n            ]\n            results = text_generation_pipeline(chat_input,\n                                               max_new_tokens=400,\n                                               do_sample=True,\n                                               temperature=1.1,\n                                               top_p=0.9)\n            gc.collect()\n            torch.cuda.empty_cache()\n            entities = []\n            for result in results:\n                generated_text = result[0]['generated_text']\n                entity = extract_json_from_response(generated_text)\n                if entity == []:\n                    failed_animal_names.append(prompt)\n                else:\n                    entities.append(entity)\n            \n            write_batch_to_json(entities, i) \n\n\nos.makedirs(\"/kaggle/working/generated/\", exist_ok=True)\n\nprocessed_data = predict_entities_in_batches(prev_failed_animal_names, model, tokenizer, system_prompt)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filename = \"/kaggle/working/failed_animal_names.json\"\nwith open(filename, \"w\", encoding='utf-8') as f:\n    json.dump({\"failed_animal_names\": failed_animal_names}, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:27:39.426255Z","iopub.execute_input":"2025-02-19T19:27:39.427085Z","iopub.status.idle":"2025-02-19T19:27:39.431732Z","shell.execute_reply.started":"2025-02-19T19:27:39.427045Z","shell.execute_reply":"2025-02-19T19:27:39.430825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/generated', \"zip\", '/kaggle/working/generated/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T19:27:39.602436Z","iopub.execute_input":"2025-02-19T19:27:39.603025Z","iopub.status.idle":"2025-02-19T19:27:39.611020Z","shell.execute_reply.started":"2025-02-19T19:27:39.602989Z","shell.execute_reply":"2025-02-19T19:27:39.610105Z"}},"outputs":[],"execution_count":null}]}