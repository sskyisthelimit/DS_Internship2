{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":840806,"sourceType":"datasetVersion","datasetId":59760}],"dockerImageVersionId":30461,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:30:55.509744Z","iopub.execute_input":"2025-02-19T13:30:55.509982Z","iopub.status.idle":"2025-02-19T13:30:55.537319Z","shell.execute_reply.started":"2025-02-19T13:30:55.509958Z","shell.execute_reply":"2025-02-19T13:30:55.536397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport random\nimport os\nfrom pathlib import Path\n\n# Import visualization libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport cv2\nimport seaborn as sns\n\n# PyTorch & torchvision\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms, models\n\n# Metrics\nfrom sklearn.metrics import classification_report, accuracy_score\n\nsns.set_style('darkgrid')\n\n# %%\ndef seed_everything(seed=42):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.use_deterministic_algorithms(True)\n\nseed_everything()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:30:55.538990Z","iopub.execute_input":"2025-02-19T13:30:55.539238Z","iopub.status.idle":"2025-02-19T13:30:59.401260Z","shell.execute_reply.started":"2025-02-19T13:30:55.539214Z","shell.execute_reply":"2025-02-19T13:30:59.400395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATASET_DIR = \"/kaggle/input/animals10/raw-img\"  # adjust as needed\nBATCH_SIZE = 32\nTARGET_SIZE = (224, 224)\ndef convert_path_to_df(dataset):\n    image_dir = Path(dataset)\n    # Look for multiple image extensions\n    filepaths = list(image_dir.glob('**/*.JPG')) + list(image_dir.glob('**/*.jpg')) + \\\n                list(image_dir.glob('**/*.jpeg')) + list(image_dir.glob('**/*.PNG'))\n    # Assume the parent folder name is the label\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n    image_df = pd.concat([filepaths, labels], axis=1)\n    return image_df\n\nimage_df = convert_path_to_df(DATASET_DIR)\n\n# Create a numeric label column\nunique_labels = sorted(image_df['Label'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:30:59.402591Z","iopub.execute_input":"2025-02-19T13:30:59.403552Z","iopub.status.idle":"2025-02-19T13:32:04.726125Z","shell.execute_reply.started":"2025-02-19T13:30:59.403512Z","shell.execute_reply":"2025-02-19T13:32:04.725312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:32:04.727198Z","iopub.execute_input":"2025-02-19T13:32:04.727470Z","iopub.status.idle":"2025-02-19T13:32:04.739899Z","shell.execute_reply.started":"2025-02-19T13:32:04.727444Z","shell.execute_reply":"2025-02-19T13:32:04.738884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(unique_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:32:04.741178Z","iopub.execute_input":"2025-02-19T13:32:04.741634Z","iopub.status.idle":"2025-02-19T13:32:04.747268Z","shell.execute_reply.started":"2025-02-19T13:32:04.741577Z","shell.execute_reply":"2025-02-19T13:32:04.746287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_mapping = {\n    'cane': 'dog',\n    'cavallo': 'horse',\n    'elefante': 'elephant',\n    'farfalla': 'butterfly',\n    'gallina': 'chicken',\n    'gatto': 'cat',\n    'mucca': 'cow',\n    'pecora': 'sheep',\n    'ragno': 'spider',\n    'scoiattolo': 'squirrel'\n}\nunique_labels = ['dog', 'horse', 'elephant', 'butterfly', 'chicken', 'cat', 'cow', 'sheep', 'spider', 'squirrel']\n# Assuming your DataFrame is named 'df' and the column with labels is 'Label'\nimage_df['Label'] = image_df['Label'].map(label_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:32:04.748412Z","iopub.execute_input":"2025-02-19T13:32:04.748730Z","iopub.status.idle":"2025-02-19T13:32:04.764110Z","shell.execute_reply.started":"2025-02-19T13:32:04.748704Z","shell.execute_reply":"2025-02-19T13:32:04.763175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\nidx_to_label = {idx: label for label, idx in label_to_idx.items()}\nimage_df['Label_idx'] = image_df['Label'].map(label_to_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:32:04.767846Z","iopub.execute_input":"2025-02-19T13:32:04.768466Z","iopub.status.idle":"2025-02-19T13:32:04.779831Z","shell.execute_reply.started":"2025-02-19T13:32:04.768440Z","shell.execute_reply":"2025-02-19T13:32:04.778976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import PIL\nfrom PIL import UnidentifiedImageError, Image\n\nfor img_p in Path(DATASET_DIR).rglob(\"*.jpg\"):\n    try:\n        img = PIL.Image.open(img_p)\n    except UnidentifiedImageError:\n        print(f'Could not identify image: {img_p}')\n\n# %%\n# Get the value counts for each label and plot distribution\nlabel_counts = image_df['Label'].value_counts()\n\nfig, ax = plt.subplots(figsize=(20, 6))\nsns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='pastel', ax=ax)\nax.set_title('Distribution of Labels in Image Dataset', fontsize=16)\nax.set_xlabel('Label', fontsize=14)\nax.set_ylabel('Count', fontsize=14)\nax.set_xticklabels(label_counts.index, rotation=45)\nfig.suptitle('Image Dataset Label Distribution', fontsize=20)\nfig.subplots_adjust(top=0.85)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:32:04.780950Z","iopub.execute_input":"2025-02-19T13:32:04.781197Z","iopub.status.idle":"2025-02-19T13:32:22.038653Z","shell.execute_reply.started":"2025-02-19T13:32:04.781174Z","shell.execute_reply":"2025-02-19T13:32:22.037638Z"},"id":"s14XOEp01m_s","papermill":{"duration":0.122033,"end_time":"2022-10-10T07:48:09.059708","exception":false,"start_time":"2022-10-10T07:48:08.937675","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display 16 picture of the dataset with their labels\nrandom_index = np.random.randint(0, len(image_df), 16)\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n    ax.set_title(image_df.Label[random_index[i]])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:32:22.039836Z","iopub.execute_input":"2025-02-19T13:32:22.040111Z","iopub.status.idle":"2025-02-19T13:32:23.270809Z","shell.execute_reply.started":"2025-02-19T13:32:22.040086Z","shell.execute_reply":"2025-02-19T13:32:23.269540Z"},"id":"m4WJVJ7j1rU9","outputId":"777f0f9a-e46c-4475-ca6a-97a4e6fb89a3","papermill":{"duration":1.190226,"end_time":"2022-10-10T07:48:10.343152","exception":false,"start_time":"2022-10-10T07:48:09.152926","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_ela_cv(path, quality):\n    temp_filename = 'temp_file_name.jpeg'\n    SCALE = 15\n    orig_img = cv2.imread(path)\n    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n    \n    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n\n    # read compressed image\n    compressed_img = cv2.imread(temp_filename)\n\n    # get absolute difference between img1 and img2 and multiply by scale\n    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n    return diff\n\n\ndef random_sample(path, extension=None):\n    if extension:\n        items = Path(path).glob(f'*.{extension}')\n    else:\n        items = Path(path).glob(f'*')\n        \n    items = list(items)\n        \n    p = random.choice(items)\n    return p.as_posix()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-02-19T13:32:23.272391Z","iopub.execute_input":"2025-02-19T13:32:23.272742Z","iopub.status.idle":"2025-02-19T13:32:23.280818Z","shell.execute_reply.started":"2025-02-19T13:32:23.272710Z","shell.execute_reply":"2025-02-19T13:32:23.279774Z"},"papermill":{"duration":0.031029,"end_time":"2022-10-10T07:48:10.430201","exception":false,"start_time":"2022-10-10T07:48:10.399172","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View random sample from the dataset\np = random_sample('/kaggle/input/animals10/raw-img/cane')\norig = cv2.imread(p)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0\ninit_val = 100\ncolumns = 3\nrows = 3\n\nfig=plt.figure(figsize=(15, 10))\nfor i in range(1, columns*rows +1):\n    quality=init_val - (i-1) * 8\n    img = compute_ela_cv(path=p, quality=quality)\n    if i == 1:\n        img = orig.copy()\n    ax = fig.add_subplot(rows, columns, i) \n    ax.title.set_text(f'q: {quality}')\n    plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:32:23.281921Z","iopub.execute_input":"2025-02-19T13:32:23.282210Z","iopub.status.idle":"2025-02-19T13:32:25.028563Z","shell.execute_reply.started":"2025-02-19T13:32:23.282181Z","shell.execute_reply":"2025-02-19T13:32:25.026892Z"},"papermill":{"duration":1.189411,"end_time":"2022-10-10T07:48:11.637574","exception":false,"start_time":"2022-10-10T07:48:10.448163","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separate in train and test data\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:32:25.029977Z","iopub.execute_input":"2025-02-19T13:32:25.031028Z","iopub.status.idle":"2025-02-19T13:32:25.040325Z","shell.execute_reply.started":"2025-02-19T13:32:25.030993Z","shell.execute_reply":"2025-02-19T13:32:25.039334Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AnimalDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.loc[idx, 'Filepath']\n        image = Image.open(img_path).convert('RGB')\n        label = int(self.dataframe.loc[idx, 'Label_idx'])\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ntrain_transform = transforms.Compose([\n    transforms.Resize(TARGET_SIZE),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),  # degrees\n    transforms.RandomAffine(degrees=0, scale=(0.9, 1.1)),  # simulate zoom\\n    transforms.ColorJitter(contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_transform = transforms.Compose([\n    transforms.Resize(TARGET_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:32:25.041502Z","iopub.execute_input":"2025-02-19T13:32:25.041878Z","iopub.status.idle":"2025-02-19T13:32:25.050679Z","shell.execute_reply.started":"2025-02-19T13:32:25.041845Z","shell.execute_reply":"2025-02-19T13:32:25.049720Z"},"id":"3puUVDwl2Mcz","papermill":{"duration":0.042276,"end_time":"2022-10-10T07:48:11.867829","exception":false,"start_time":"2022-10-10T07:48:11.825553","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = AnimalDataset(train_df, transform=train_transform)\nval_dataset = AnimalDataset(test_df, transform=test_transform)  # using test_df as validation for now\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:38:49.406385Z","iopub.execute_input":"2025-02-19T13:38:49.407107Z","iopub.status.idle":"2025-02-19T13:38:49.413571Z","shell.execute_reply.started":"2025-02-19T13:38:49.407073Z","shell.execute_reply":"2025-02-19T13:38:49.412660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.efficientnet_v2_m(weights='DEFAULT')\n\n# Freeze the feature extractor\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:42:39.716221Z","iopub.execute_input":"2025-02-19T13:42:39.716924Z","iopub.status.idle":"2025-02-19T13:42:40.793217Z","shell.execute_reply.started":"2025-02-19T13:42:39.716889Z","shell.execute_reply":"2025-02-19T13:42:40.792390Z"},"id":"z4VI_UxV2Wp2","papermill":{"duration":2.633611,"end_time":"2022-10-10T07:48:18.524309","exception":false,"start_time":"2022-10-10T07:48:15.890698","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nin_features = model.classifier[1].in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(in_features, 128),\n    nn.ReLU(),\n    nn.BatchNorm1d(128),\n    nn.Dropout(0.45),\n    nn.Linear(128, 256),\n    nn.ReLU(),\n    nn.BatchNorm1d(256),\n    nn.Dropout(0.45),\n    nn.Linear(256, len(unique_labels))  # number of classes\n)\n\nmodel = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\nDEVICE = next(model.parameters()).device\n\n# %%\n# Loss, Optimizer, and Learning Rate Scheduler\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:42:44.591127Z","iopub.execute_input":"2025-02-19T13:42:44.591988Z","iopub.status.idle":"2025-02-19T13:42:45.978923Z","shell.execute_reply.started":"2025-02-19T13:42:44.591952Z","shell.execute_reply":"2025-02-19T13:42:45.978123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 25\nbest_val_loss = np.inf\n\npatience = 5\nepochs_without_improvement = 0\n\ntrain_history = {'loss': [], 'acc': []}\nval_history = {'loss': [], 'acc': []}\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    train_loss = running_loss / total\n    train_acc = 100 * correct / total\n    train_history['loss'].append(train_loss)\n    train_history['acc'].append(train_acc)\n    \n    model.eval()\n    val_running_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_running_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n    val_loss = val_running_loss / val_total\n    val_acc = 100 * val_correct / val_total\n    val_history['loss'].append(val_loss)\n    val_history['acc'].append(val_acc)\n    \n    scheduler.step(val_loss)\n    \n    print(f'Epoch {epoch+1}/{num_epochs} -- Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_without_improvement = 0\n        torch.save(model.state_dict(), 'animals_classification_model_checkpoint.pth')\n    else:\n        epochs_without_improvement += 1\n\n    if epochs_without_improvement >= patience:\n        print(\"Early stopping triggered.\")\n        break\n\n\n# %%\n# Load the best model for evaluation\nmodel.load_state_dict(torch.load('animals_classification_model_checkpoint.pth'))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:42:49.696964Z","iopub.execute_input":"2025-02-19T13:42:49.697302Z","iopub.status.idle":"2025-02-19T13:47:42.390647Z","shell.execute_reply.started":"2025-02-19T13:42:49.697273Z","shell.execute_reply":"2025-02-19T13:47:42.389764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nall_preds = []\nall_labels = []\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(DEVICE)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\ntest_loss = np.mean([criterion(model(images.to(DEVICE)), labels.to(DEVICE)).item()\n                      for images, labels in val_loader])\nprint(f\"Test Loss: {test_loss:.5f}\")\nprint(f\"Test Accuracy: {accuracy_score(all_labels, all_preds)*100:.2f}%\")\n\n# %%\n# Plot Training History\nepochs_range = range(len(train_history['loss']))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\nax1.plot(epochs_range, train_history['acc'], 'b', label='Training Accuracy')\nax1.plot(epochs_range, val_history['acc'], 'r', label='Validation Accuracy')\nax1.set_title('Training and Validation Accuracy')\nax1.set_xlabel('Epochs')\nax1.set_ylabel('Accuracy')\nax1.legend()\n\nax2.plot(epochs_range, train_history['loss'], 'b', label='Training Loss')\nax2.plot(epochs_range, val_history['loss'], 'r', label='Validation Loss')\nax2.set_title('Training and Validation Loss')\nax2.set_xlabel('Epochs')\nax2.set_ylabel('Loss')\nax2.legend()\n\nfig.suptitle('Training and Validation Metrics', fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:49:17.024824Z","iopub.execute_input":"2025-02-19T13:49:17.025203Z","iopub.status.idle":"2025-02-19T13:51:01.210045Z","shell.execute_reply.started":"2025-02-19T13:49:17.025173Z","shell.execute_reply":"2025-02-19T13:51:01.209070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict the labels for the validation set\nmodel.eval()\nall_val_preds = []\nwith torch.no_grad():\n    for images, _ in val_loader:\n        images = images.to(DEVICE)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_val_preds.extend(preds.cpu().numpy())\n\n# Map numeric labels back to class names\npred_labels = [idx_to_label[p] for p in all_val_preds]\nprint(f'The first 5 predictions: {pred_labels[:5]}')\n\n# %%\n# Display 15 random images from the test set with true and predicted labels\nrandom_idx = np.random.randint(0, len(test_df), 15)\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15), subplot_kw={'xticks': [], 'yticks': []})\n\n# Get predictions for the entire test set\ntest_loader_full = DataLoader(AnimalDataset(test_df, transform=test_transform), batch_size=BATCH_SIZE, shuffle=False)\nall_test_preds = []\nwith torch.no_grad():\n    for images, _ in test_loader_full:\n        images = images.to(DEVICE)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_test_preds.extend(preds.cpu().numpy())\n\nfor i, ax in enumerate(axes.flat):\n    idx = random_idx[i]\n    img = plt.imread(test_df.Filepath.iloc[idx])\n    true_label = test_df.Label.iloc[idx]\n    pred_label = idx_to_label[all_test_preds[idx]]\n    color = \"green\" if true_label == pred_label else \"red\"\n    ax.imshow(img)\n    ax.set_title(f\"True: {true_label}\\nPredicted: {pred_label}\", color=color)\nplt.tight_layout()\nplt.show()\n\n# %%\n# Compute and display classification report\ny_true = list(test_df.Label)\ny_pred = [idx_to_label[p] for p in all_test_preds]\nprint(classification_report(y_true, y_pred))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:51:26.577482Z","iopub.execute_input":"2025-02-19T13:51:26.577862Z","iopub.status.idle":"2025-02-19T13:53:13.089430Z","shell.execute_reply.started":"2025-02-19T13:51:26.577829Z","shell.execute_reply":"2025-02-19T13:53:13.088442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"report = classification_report(y_true, y_pred, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\nprint(df_report)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T13:53:13.091085Z","iopub.execute_input":"2025-02-19T13:53:13.091382Z","iopub.status.idle":"2025-02-19T13:53:13.110134Z","shell.execute_reply.started":"2025-02-19T13:53:13.091355Z","shell.execute_reply":"2025-02-19T13:53:13.108864Z"},"id":"bYWvkbXI4Ns2","outputId":"7e04d8a2-3263-4a31-d469-70d8140cb167","papermill":{"duration":0.363746,"end_time":"2022-10-10T07:56:42.071383","exception":false,"start_time":"2022-10-10T07:56:41.707637","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}